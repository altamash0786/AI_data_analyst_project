# -*- coding: utf-8 -*-
"""week3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-GDRSMvhFJREEUtSepEGohNfdJwpvlN7

Task  1. Building Predictive Models:

Task: Develop and train machine learning models to predict student drop-offs.

Goal: Create models that accurately forecast student churn.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Load the Data
file_path = '/content/Week1_data.csv'
data = pd.read_csv(file_path)

# Step 2: Explore the Data
print("Data Overview:")
print(data.head())
print("\nMissing Values:")
print(data.isnull().sum())
print("\nData Types:")
print(data.dtypes)

# Step 3: Handle Missing Values (if any)
# Fill numeric missing values with median
data.fillna(data.select_dtypes(include=[np.number]).median(), inplace=True)

# Fill categorical missing values with mode using a dictionary
mode_values = data.select_dtypes(include=['object']).mode().iloc[0]  # Get first mode for each column
data.fillna(mode_values, inplace=True)  # Fill categorical columns

# Step 4: Encode Categorical Variables
label_encoders = {}
for column in data.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    data[column] = le.fit_transform(data[column])
    label_encoders[column] = le

print(data.columns)

target_column = 'Opportunity Category'

data.columns = data.columns.str.strip()  # Remove spaces around column names

data.columns = data.columns.str.replace('_', ' ').str.title()  # Convert to title case
print(data.columns)

# Step 5: Define Features and Target
target_column = 'Opportunity End Date'
X = data.drop(columns=[target_column])
y = data[target_column]

# Step 6: Split the Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 7: Normalize the Features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Step 8: Train a Predictive Model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 9: Evaluate the Model
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nModel Accuracy: {accuracy:.2f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""2. Evaluating Model Performance:

Task: Assess models using metrics like accuracy and precision.

Goal: Ensure models provide reliable predictions.
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

y_pred = model.predict(X_test)

# Accuracy: Overall correctness of the model
accuracy = accuracy_score(y_test, y_pred)

# Precision: How many predicted positives were actually positive?
precision = precision_score(y_test, y_pred, average='weighted')

# Recall: How many actual positives were correctly predicted?
recall = recall_score(y_test, y_pred, average='weighted')

# F1 Score: Harmonic mean of precision and recall
f1 = f1_score(y_test, y_pred, average='weighted')

# Confusion Matrix: Visual representation of classification performance
conf_matrix = confusion_matrix(y_test, y_pred)

# Classification Report: Detailed precision, recall, and F1-score for each class
class_report = classification_report(y_test, y_pred)

# Display results
print(f"ðŸ˜Š Accuracy: {accuracy:.2f}")
print(f"ðŸ˜Š Precision: {precision:.2f}")
print(f"ðŸ˜Š Recall: {recall:.2f}")
print(f"ðŸ˜Š F1 Score: {f1:.2f}")
print("\nðŸ˜Š Confusion Matrix:\n", conf_matrix)
print("\nðŸ˜Š Classification Report:\n", class_report)